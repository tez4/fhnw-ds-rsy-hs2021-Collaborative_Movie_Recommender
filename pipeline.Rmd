---
title: "Collaborative Movie Recommender"
author: "Pascal Berger, Lea Bütler & Joël Grosjean"
output:
  html_notebook: default
  pdf_document: default
---
R-Version: **[Default] [32-bit] C:\\Program Files\\R\\R-4.1.0**

```{r echo=FALSE, cache=FALSE, results=FALSE, comment=FALSE, warning=FALSE}
# nötige Packete
packages <- c("tidyverse", "data.table", "lubridate", "ggplot2", "ggthemes", "recommenderlab", "knitr", 'pals', 'RColorBrewer', 'lattice')

# Noch nicht installierte Pakete installieren
installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Laden der Packete
invisible(lapply(packages, library, character.only = TRUE))

# Importieren von Funktionene aus helper file
source("helper.R")

# change options
options(dplyr.summarise.inform = FALSE)
```

***
#### data wrangling
```{r}
# Daten importieren
data(MovieLense)

# dataframe erstellen
movies <- as(MovieLense, "data.frame")
movies <- movies %>% mutate_if(is.character, as.factor)

# breite version des dataframe erstellen
movies_wider <- pivot_wider(
  movies,
  id_cols = user,
  names_from = item,
  values_from = rating,
  values_fill = NULL,
)
```

***
## Explorative Datenanalyse
```{r}
df_1 <- movies %>% group_by(item) %>%  summarize(mean_rating = mean(rating)) %>% sample_n(15) %>% arrange(desc(mean_rating))

ggplot(df_1, aes(y = reorder(item, +mean_rating), x = mean_rating)) +
  geom_col(alpha = 1, fill = 'steelblue') +
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(mean_rating,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Durchschnittliche Filmbewertung",
    subtitle = "Zufällige Stichprobe von 15 Filmen",
    y = element_blank(),    x = "Dirchschnittlich Bewertung in Sternen"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )

```
TODO: beschreiben was das bringt


***
#### 1. Welches sind die am häufigsten geschauten Genres / Filme?
```{r}
movies_genre <- MovieLenseMeta %>%
  rename(item = title)
movies_genre$url <- NULL
movies_genre[movies_genre == 0] <- NA
a <- which(movies_genre==1,arr.ind=TRUE)
movies_genre[a] <- names(movies_genre)[a[,"col"]]
movies_genre <- movies_genre %>%
  unite("genres", unknown:Western, sep= ",", 
        remove = TRUE, na.rm = TRUE)
genres<-merge(x=movies,y=movies_genre,by="item",all.x=TRUE)%>%
  mutate(genres = strsplit(as.character(genres), ",")) %>%
  unnest(genres)

df1a <- movies%>%
  group_by(item)%>%
  summarize(count=n())%>%
  ungroup()%>%
  arrange(desc(count))

df1a <- head(df1a, 10)

df1a %>%
  mutate(item = fct_reorder(item, count))%>%
  ggplot(aes(x = count, y = item))+
  geom_col(alpha = 1, fill = 'steelblue')+
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(count,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Meist bewertete Filme",
    y = element_blank(),    x = "Anzahl Bewertungen"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )
```
Da in unserem Datensatz nur die Anzahl Ratings von Filmen gegeben ist, gehen wir davon aus, dass die meist bewerteten, auch die am meist geschauten Filme sind. In der Grafik sieht man die 10 meist bewerteten Filme.

```{r}
df1b <- genres%>%
  group_by(genres)%>%
  summarize(count=n())%>%
  ungroup()%>%
  arrange(desc(count))

df1b%>%
  mutate(genres = fct_reorder(genres, count))%>%
  ggplot(aes(x = count, y = genres))+
  geom_col(alpha = 1, fill = 'steelblue')+
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=count,2), hjust = 1.3, color = 'white') +
  labs(
    title = "Meist bewertete Genres",
    y = element_blank(),    x = "Anzahl Bewertungen"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )
```
TODO: Anzahl hinzufügen

Auch hier wird davon ausgegangen, dass die enres, welche am häufigsten bewertet wurden auch am häufigst geschaut wurden. In der Grafik ist zu sehen, dass Drama das top Genres ist, gefolgt von Comedy und Action.

***
#### 2. Wie verteilen sich die Kundenratings gesamthaft und nach Genres?
```{r}
ggplot(movies, aes(x = rating)) +
  geom_bar(alpha = 1, fill = 'steelblue') +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung Kundenratings gesamthaft",
    subtitle = paste("N = ", nrow(movies), " Bewertungen"),
    x = "Kundenbewertungen", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  theme_classic() +
  theme(
    text = element_text(size = 12)
  )
```
In dieser Grafik ist die Verteilung der bewertungen zu sehen. Die Bewertungen 4 und 5 wirden klar am häufigsten vergeben, wobei 1 und 2 eher selten bewertet werden.

```{r warning=FALSE}
# get rating count per user, add as column for further processing
counts <- movies %>% group_by(user) %>% count()
movies2 <- merge(movies, counts, by="user")
movies_wider2 <- merge(movies_wider, counts, by="user")

# avoid users with almost no ratings, use median as threshold
median_count <- median(counts$n)

# get sample
set.seed(623)
movies_sample <- movies_wider2 %>% filter(n > median_count) %>% sample_n(5)

# create long table
movies_sample_long <- filter(movies2, user %in% movies_sample$user)

# drop item names, 
movies_sample_long <- subset(movies_sample_long, select = -c(item))

df2b <- genres%>%
  group_by(genres)
  
movies_sample_long_grouped <- movies_sample_long %>% group_by(user, rating) %>% summarise(rating_dens = length(user) / first(n), user = first(user), n=first(n), rating = first(rating))
  
ggplot(genres, aes(x = rating, fill = genres)) +
  geom_bar(alpha = 1, bins = 10) +
  facet_wrap(~genres)+
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung Kundenratings nach Genres",
    subtitle = paste("N = ", nrow(movies), " Bewertungen"),
    x = "Durchschnittliche Bewertung", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  theme(
    text = element_text(size = 12),
    legend.position = 'none'
  )
```
Hier ist zu sehen, dass das Genres Drama am meisten bewertet wurde, wobei Dokumentationen am wenigsten Bewertungen erhalten haben. Die Bewertungen pro Genres verteilen sich jeweils sehr ähnlich. Die Verteilungen der einzelnen Genres sind ebenfalls ähnlich verteilt wie die bewertungen gesamthaft.

***
#### 3.Wie verteilen sich die mittleren Kundenratings pro Film?
```{r}
df3 <- movies %>% 
  group_by(item) %>%  
  summarize(
    mean_rating = mean(rating),
    ratings = n()
  ) %>% 
  mutate(
    more_than_50 = ifelse(ratings >= 50, 'b) mehr als 50 Bewertungen', 'a) weniger als 50 Bewertugen')
  )

ggplot(df3, aes(x = mean_rating)) +
  geom_histogram(alpha = 1, fill = 'steelblue', binwidth = 0.06) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung mittlere Kundenratings pro Film",
    subtitle = paste("N = ", nrow(df3), " Filme"),
    x = "Durchschnittliche Bewertung", 
    y = "Dichte"
  ) +
  theme_classic() +
  theme(text = element_text(size = 12)
  )
```
In dieser Grafik ist die durchschnittliche Bewertung pro Film zu sehen, wobei auch hier zu sehen ist ,dass die die meisten Filme eine Durchschnittliche Bewertung von ca. 3 - 3.5 haben.

```{r}
ggplot(df3, aes(x = mean_rating, fill = more_than_50)) +
  geom_density(alpha = 0.5, bw = 0.08) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung mittlere Kundenratings pro Film",
    subtitle = "N = 1664 Filme",
    x = "Durchschnittliche Bewertung", 
    y = "Dichte",
    fill = element_blank()
  ) +
  theme_classic() +
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
Für diese Grafik wurden die Filme in zwei gruppen unterteilt: Filme die weniger als 50 bewertungen erhalten haben, und Filme welche mehr als 50 Bewertungen erhalten haben. In der Grafik ist imernoch die durchschnittliche Bewertung dieser Filme zu sehen wobei deutlich erkannt werden kann, dass filme welche weniger bewertungen erhalten haben, tendenziell auch schlechter bewertet wurden.

***
#### 4.Wie stark streuen die Ratings von individuellen Kunden?
```{r}
# Number of ratings per user per rating value
movies_sample_long_grouped <- movies_sample_long %>% group_by(user, rating) %>% summarise(rating_dens = length(user) / first(n), user = first(user), n=first(n), rating = first(rating))
```
```{r}
movies_span <- movies %>% group_by(user) %>% 
  summarize(mean = mean(rating), min = min(rating), max = max(rating), span = (max(rating) - min(rating)))

set.seed(123)

ggplot(movies_span, aes(x=user)) +
  geom_bar(aes(span), fill = 'steelblue') +
  scale_y_continuous(expand = c(0,0)) +
  labs(
    title = "Spannweite Kundenratings",
    subtitle = "",
    x = "Spannweite", 
    y = "Anzahl User"
  )+
    theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
  
```
TODO: Anzahl

0In diesen Grafiken sehen wir detailliertere Informationen über die Spannweite und den Mittelpunkt. In der ersten Übersicht ist die Spannweite und der Mittelpunkt einzelner Kunden dargestellt. Es fällt auf, dass trotz des teilweise relativ hohem Mittelwert alle Ratings von 1-5 abgegeben wurden. Ein rating von 5 wurde sozusagen immer abgegeben, 1 nicht immer.
In der zweiten Übersicht ist die Spannweite aller Kunden dargestellt. Hier wird sichtbar, dass die meisten Kunden Bewertungen von 1-5 abgegeben haben (Spannweite=4), und nur weinige sehr homogen bewertet haben (Spannweite = 1-2). Eine kleine Spannweite kann hier auch aufgetreten sein, da diese User sehr wenige Bewertungen abgegeben haben.

***
#### 5.Welchen Einfluss hat die Normierung der Ratings pro Kunde auf deren Verteilung?
```{r}
movies_sample_long_grouped <- movies %>% group_by(rating) %>% summarise(rating_dens = n())

ggplot(movies_sample_long_grouped, aes(x=rating, y = rating_dens)) + 
  geom_col(fill = 'steelblue') +
  scale_y_continuous(expand = c(0,0)) +
  labs(
    title = "Häufigkeit der Kundenbewertungen",
    subtitle = "N = 943 Kunden",
    x = "User Bewertung (1-5)", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
                    )+
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
TODO: ANzahl RAtings, N = Anzahl Ratings

```{r}
MovNorm <- normalize(MovieLense, method="Z-score")
mov <- as(MovNorm, "data.frame")

ggplot(mov, aes(x=rating)) + 
  geom_histogram(fill = 'steelblue', bins = 70) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Häufigkeit der Kundenbewertungen",
    subtitle = "N = 943 Kunden",
    x = "User Bewertung Normiert", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
                    )+
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
TODO: N = Anzahl Ratings

Die Ratings sind nun ungefähr Normalverteilt mit einem Durchschnittsrating von 0 und einer Standardabweichung von 1. 
Erkennbar ist, dass die Verteilung rechtssteil und linksschief ist, also mehrheitlich positive Bewertungen abgegeben wurden. 
Durch die Normierung der Daten werden die Ratings jedes Users auf dieselbe Verteilung gestaucht, wodurch man die Verteilung aller Daten analysieren kann. Dadurch hat man beispielsweise die Möglichkeit die durchschnittliche Bewertungstendenz herauszufinden. 

***
#### 6.Welche strukturellen Charakteristika (z.B. Sparsity) und Auffälligkeiten zeigt die User Item Matrix?
```{r}
image(MovieLense, main = "Raw Ratings")
# MovieLenseNorm <- normalize(MovieLense, method="Z-score")
```
Users mit tiefen ID's und Filme mit hohen ID's weisen weniger ratings auf. Filme mit tiefer ID jedoch sehr viele.
Auffallend ist, dass es einige wenige User gibt, die fast alle Filme bewertet haben (erkennbar durch die horizontalen scharzen Striche). Dies scheinen sehr aktive Bewerter zu sein.
Viele Users haben jedoch nur einen kleinen Teil der Filme bewertet.
Bei den Filmen ist eine ähnliche Tendenz wahrzunehmen, jedoch sind die vertikalen Striche breiter. Möglicherweise sind dort einige beliebte Filme zusammengefasst.

TODO: Sparcity anzeigen
TODO: Colorbar entfernen

***
## Datenreduktion
```{r}
ratingMatrix <- data_reduction_dense(MovieLense)
ratingMatrix
```

```{r}
show_sparsity_change(MovieLense, ratingMatrix)
```
TODO: Zwei mehr datenreduktiuonen hinzufügen (1x Random, 1x Users with most ratings, but Movies random)
TODO: Bessere namen für Matrizen
TODO: Als plot darstellen

```{r}
image(ratingMatrix, main = "Raw Ratings")
```
Man sieht sehr klar, dass die matrix nun deutlich weniger sparse ist.

TODO: Plot für verschiedene Datenreduktionen

```{r}
show_change_of_rating_distribution(MovieLense, ratingMatrix)
```
TODO: N von plot anpassen (auch N für b) darstellen)
TODO: Plot für verschiedene Datenreduktionen

***
## Analyse Ähnlichkeitsmatrix
#### 1. Zerlege den reduzierten MovieLense Datensatz in ein disjunktes Trainings- und Testdatenset im Verhältnis 4:1
```{r}
both <- split_dataset(ratingMatrix, 0.8)
train <- both[[1]]
test <- both[[2]]

print('Trainingsdatenset:')
dim(train)
print('')
print('Testdatenset:')
dim(test)
```

***
#### 2. Trainiere ein IBCF Modell mit 30 Nachbarn und Cosine Similarity
```{r}

rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center'
rec

# predict top 10 movies for 100 users
pre <- predict(rec, test, n = 10)
pre

reco_list <- as(pre, "list")

# top 10 recommendations for the 13th user in reco_list
reco_list[13]

#image(as(pre, "matrix"))

```
***
#### 3. Bestimme die Verteilung der Filme, welche bei IBCF für paarweise Ähnlichkeitsvergleiche verwendet werden
```{r}
model <- getModel(rec)
colSum <- colSums(model$sim > 0)

df <- as.data.frame(colSum)

# add index column
df <- cbind(item = rownames(df), df)
rownames(df) <- 1:nrow(df)

ggplot(df, aes(x = colSum)) +
  geom_histogram(alpha = 1, fill = 'steelblue', binwidth = 2) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung der Anzahl ähnlicher Filme",
    # subtitle = paste("N = ", nrow(df3), " Filme"),
    x = "Anzahl Filme bei denen der Film als Nachbar auftaucht", 
    y = "Häufigkeit"
  ) +
  theme_classic() +
  theme(text = element_text(size = 12)
  )

# ggplot(movies_sample_long_grouped, aes(x=rating, y = rating_dens)) + 
#   geom_col(fill = 'steelblue') +
#   scale_y_continuous(expand = c(0,0)) +
#   labs(
#     title = "Häufigkeit der Kundenbewertungen",
#     subtitle = "N = 943 Kunden",
#     x = "User Bewertung (1-5)", 
#     y = "Anzahl",
#     fill = element_blank()
#   ) +
#   scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
#                     )+
#   theme_classic() + 
#   theme(
#     text = element_text(size = 12),
#     legend.position = 'bottom'
#   )
```
TODO: gute beschreibung

***
#### 4. Bestimme die Filme, die am häufigsten in der Cosine-Ähnlichkeitsmatrix auftauchen und analysiere deren Vorkommen und Ratings im reduzierten Datensatz
```{r}
df1 <- df %>% arrange(desc(colSum)) %>% head(10)

ggplot(df1, aes(x = colSum, y = reorder(item, +colSum)))+
  geom_col(alpha = 1, fill = 'steelblue')+
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(colSum,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Häufigste Filme in Cosine-Ähnlichkeitsmatrix",
    y = element_blank(),
    x = "Anzahl Filme in deren Nachbarschaft der Film ist"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )
```

```{r}
top10 <- as.list(df1)$item

data <- as(ratingMatrix, "data.frame")
data1 <- data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating)) %>%
  arrange(desc(mean_rating)) %>%
  mutate(category = ifelse(item %in% top10, 'Häufigste 10 Filme', 'Restliche Filme'))

ggplot(data1, aes(x = mean_rating, fill = category)) +
  geom_density(alpha = 0.5, bw = 0.05) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung mittlere Kundenratings pro Film",
    x = "Durchschnittliche Bewertung",
    y = "Dichte",
    fill = element_blank()
  ) +
  theme_classic() +
  theme(
    text = element_text(size = 12),
    legend.position = c(.14, .93)
  )
```
Es fällt auf, dass die häufigsten Filme allgemein sehr gut bewertet werden.

***
##Analyse Top-N Listen - IBCF vs. UBCF
####1.Berechne Top-15 Empfehlungen für Testkunden mit IBCF und UBCF
```{r}
rec_ibcf <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center'

# predict top 15 movies for 100 users
topn_ibcf <- predict(rec_ibcf, test, n = 15)

topn_ibcf_list <- as(topn_ibcf, "list")
#head(topn_ibcf_list, 3)

#print("------------------------")

rec_ubcf <- Recommender(train, method = "UBCF", param=list(method="Cosine", normalize = NULL))

topn_ubcf <- predict(rec_ubcf, test, n = 15)

topn_ubcf_list <- as(topn_ubcf, "list")
#head(topn_ubcf_list, 3)
```

***
####2.Vergleiche die Top-15 Empfehlungen und deren Verteilung und diskutiere Gemeinsamkeiten und Unterschiede zwischen IBCF und UBCF für alle Testkunden.
```{r}
#compare most occurring items
print("most occurring items - IBCF")
ibcf_top <- head(sort(colCounts(topn_ibcf), decreasing = TRUE))
print(ibcf_top)

print("----------------------------------------------")

print("most occurring items - UBCF")
ubcf_top <- head(sort(colCounts(topn_ubcf), decreasing = TRUE))
ubcf_top
```
TODO: darstellung als balkendiagramm

Auffällig ist, dass im UBCF die Filme, welche am häufigsten in den Top-15 Empfehlungen auftauchen, wesentlich üfters vorkommen als diese, die im IBCF als am meist vorkommende Filme definiert sind.

```{r}
#get distribution of intersect for each user
#intersect of top 15 recommendations IBCF vs UBCF
#list_comp_ibcf_ubcf <- vector(mode = "list", length = length(topn_ibcf_list))
list_comp_ibcf_ubcf <- list()
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_ubcf_list[n]))) / 15
  list_comp_ibcf_ubcf <- append(list_comp_ibcf_ubcf, intersection)
}

comp_ibcf_ubcf <- data.frame(matrix(unlist(list_comp_ibcf_ubcf), nrow=length(list_comp_ibcf_ubcf), byrow=TRUE))
colnames(comp_ibcf_ubcf) <- c('intersect')
comp_ibcf_ubcf

ggplot(comp_ibcf_ubcf, aes(x = intersect)) +
  geom_histogram(alpha = 1, fill = 'steelblue', bins = 4) +
  labs(
    title = "Verteilung der überschneidung der empfohlenen Filme",
    # subtitle = paste("N = ", nrow(df3), " Filme"),
    x = "Überschneidung in %", 
    y = "Häufigkeit"
  ) +
  theme_classic() +
  theme(text = element_text(size = 12)
  )
```
TODO: scale_continuous,.... (Plot bis zum rand)


***
## Analyse Top-N Listen - Ratings
#### Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs UBCF, beide mit ordinalem Rating und Cosine Similarity für alle Testkunden
```{r}
a <- unlist(topn_ubcf_list[1])
b <- unlist(topn_ibcf_list[1])

#intersect(a, b)

#intersect of top 15 recommendations IBCF vs UBCF cosine similarity
comp_ord_cos<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_ubcf_list[n]))) / 15
  comp_ord_cos <- comp_ord_cos + intersection
}

print('Anteil übereinstimmender Empfehlungen der Top-15 Liste: ' )
comp_ord_cos / length(topn_ibcf_list)

```



***
#### Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs UBCF, beide mit binärem Rating und Jaccard Similarity für alle Testkunden
```{r}
#ibcf recommender with Jaccard similarity
rec_ibcf_jac <- Recommender(train, method = "IBCF", param=list(method="Jaccard", k=30, normalize = NULL, na_as_zero = TRUE))
topn_ibcf_jac <- predict(rec_ibcf_jac, test, n = 15)
topn_ibcf_jac_list <- as(topn_ibcf_jac, "list")

#ubcf recommender with Jaccard similarity
rec_ubcf_jac <- Recommender(train, method = "UBCF", param=list(method="Jaccard", normalize = NULL))
topn_ubcf_jac <- predict(rec_ubcf_jac, test, n = 15)
topn_ubcf_jac_list <- as(topn_ubcf_jac, "list")

#intersect of top 15 recommendations IBCF vs UBCF Jaccard similarity
comp_bin_jac<- 0
for (n in 1:length(topn_ibcf_jac_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_jac_list[n]), unlist(topn_ubcf_jac_list[n]))) / 15
  comp_bin_jac <- comp_bin_jac + intersection
}

print('Anteil übereinstimmender Empfehlungen der Top-15 Liste: ' )
comp_bin_jac / length(topn_ibcf_jac_list)
```


***
####3.Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für UBCF mit ordinalem (Cosine Similarity) vs binärem Rating (Jaccard Similarity) für alle Testkunden.
```{r}
#intersect of top 15 recommendations UBCF Cosine Similarity vs UBCF Jaccard similarity
comp_cos_jac<- 0
for (n in 1:length(topn_ubcf_jac_list)) {
  intersection <- length(intersect(unlist(topn_ubcf_jac_list[n]), unlist(topn_ubcf_list[n]))) / 15
  comp_cos_jac <- comp_cos_jac + intersection
}

print('Anteil übereinstimmender Empfehlungen der Top-15 Liste: ')
comp_cos_jac / length(topn_ubcf_jac_list)
```
TODO: balkendiagramm mit verschiedenen Anteilen

***
##Analyse Top-N Listen - IBCF vs SVD
####1.Vergleiche wie sich der Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs verschiedene SVD Modelle verändert, wenn die Anzahl der Singulärwerte für SVD von 10 auf 20, 30, 40, 50 verändert wird
```{r}
#annahme: k  anzahl singulärwerte
#svd recommender 
rec_svd_10 <- Recommender(train, method = "SVD", param=list(k=10 ))
rec_svd_20 <- Recommender(train, method = "SVD", param=list(k=20 ))
rec_svd_30 <- Recommender(train, method = "SVD", param=list(k=30 ))
rec_svd_40 <- Recommender(train, method = "SVD", param=list(k=40 ))
rec_svd_50 <- Recommender(train, method = "SVD", param=list(k=50 ))

topn_svd_10 <- predict(rec_svd_10, test, n = 15)
topn_svd_20 <- predict(rec_svd_20, test, n = 15)
topn_svd_30 <- predict(rec_svd_30, test, n = 15)
topn_svd_40 <- predict(rec_svd_40, test, n = 15)
topn_svd_50 <- predict(rec_svd_50, test, n = 15)


topn_svd_10_list <- as(topn_svd_10, "list")
topn_svd_20_list <- as(topn_svd_20, "list")
topn_svd_30_list <- as(topn_svd_30, "list")
topn_svd_40_list <- as(topn_svd_40, "list")
topn_svd_50_list <- as(topn_svd_50, "list")

#intersect of top 15 recommendations UBCF Cosine Similarity vs SVD 10
comp_ibcf_svd_10<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_svd_10_list[n]))) / 15
  comp_ibcf_svd_10 <- comp_ibcf_svd_10 + intersection
}
print('Anteil übereinstimmender Empfehlungen der Top-15 Liste IBCF vs. SVD 10: ')
comp_ibcf_svd_10 / length(topn_ibcf_list)

#intersect of top 15 recommendations UBCF Cosine Similarity vs SVD 20
comp_ibcf_svd_20<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_svd_20_list[n]))) / 15
  comp_ibcf_svd_20 <- comp_ibcf_svd_20 + intersection
}
print('Anteil übereinstimmender Empfehlungen der Top-15 Liste IBCF vs. SVD 20: ')
comp_ibcf_svd_20 / length(topn_ibcf_list)

#intersect of top 15 recommendations UBCF Cosine Similarity vs SVD 30
comp_ibcf_svd_30<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_svd_30_list[n]))) / 15
  comp_ibcf_svd_30 <- comp_ibcf_svd_30 + intersection
}
print('Anteil übereinstimmender Empfehlungen der Top-15 Liste IBCF vs. SVD 30: ')
comp_ibcf_svd_30 / length(topn_ibcf_list)


#intersect of top 15 recommendations UBCF Cosine Similarity vs SVD 40
comp_ibcf_svd_40<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_svd_40_list[n]))) / 15
  comp_ibcf_svd_40 <- comp_ibcf_svd_40 + intersection
}
print('Anteil übereinstimmender Empfehlungen der Top-15 Liste IBCF vs. SVD 40: ')
comp_ibcf_svd_40 / length(topn_ibcf_list)


#intersect of top 15 recommendations UBCF Cosine Similarity vs SVD 50
comp_ibcf_svd_50<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_svd_50_list[n]))) / 15
  comp_ibcf_svd_50 <- comp_ibcf_svd_50 + intersection
}
print('Anteil übereinstimmender Empfehlungen der Top-15 Liste IBCF vs. SVD 50: ')
comp_ibcf_svd_50 / length(topn_ibcf_list)

```
TODO: in for-loop
TODO: Als df speichern
TODO: balkendiagramm mit verschiedenen Anteilen

***
## Wahl des optimalen Recommenders
#### Verwende für die Evaluierung 10-fache Kreuzvalidierung,

```{r}
# evaluation scheme with k=10 (10 fold cross validation) and a rating split of 5

eval_k <- 15
given_n <- 15

#scheme
scheme <- evaluationScheme(train, method = "cross-validation", k = 10, given = given_n, goodRating = 3)

algorithms <- list(
  "popular items" = list(name="POPULAR", param=NULL),
  "UBCF cosine" = list(name="UBCF", param=list(method = "cosine")),
  "IBCF cosine" = list(name="IBCF", param=list(k = eval_k, method = "cosine")),
  "IBCF pearson 30" = list(name="IBCF", param=list(k = 30, method = "pearson")),
  "IBCF pearson 90" = list(name="IBCF", param=list(k = 90, method = "pearson")),
  "SVD approximation" = list(name="SVD", param=list(k = eval_k))
)

results <- evaluate(scheme, algorithms, type = "topNList", n=c(10, 15, 20, 25, 30))
#results
#plot(results, annotate=c(1,3), legend="bottomright")
#plot(results, "prec/rec", annotate=3, legend="topleft")

```

### extract results for own plot

```{r}
ns <- c(10, 15, 20, 25, 30)

for (i in 1:length(ns)) 
{
  rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k = ns[i], normalize = 'center', na_as_zero = TRUE))
  #recom <- predict(rec, test, n=1)
  
  print(scheme)
  break
}

prrc <- data.frame( model = "", precision = 0, recall = 0, n = 0)

for (i in 1:length(avg(results)))
{
  model_result = avg(results)[[i]]
  #print(model_result)
  alg <- names(algorithms)[i]
  for (j in 1:length(model_result[, 'precision']))
  {
    pr <- model_result[, 'precision'][j]
    rc <- model_result[, 'recall'][j]
    n <- ns[j]
    prrc <- rbind(prrc, c(alg, pr, rc, n))
  }
}

prrc <- prrc[-1,]
#dtype conversion
prrc[,2] <- as.numeric(prrc[,2])
prrc[,3] <- as.numeric(prrc[,3])
prrc[,4] <- as.numeric(prrc[,4])


ggplot(data=prrc, aes(x=recall, y=precision, color=model)) + 
  geom_line() + 
  geom_text(aes(label=n), vjust=-.2, hjust=-.0, show.legend = FALSE) +
  labs(
    title = "Precision vs Recall",
    y = "Precision",
    x = "Recall"
  )
```

TODO: pearson vs cosine bei UBCF
TODO: Jaccard
TODO: Given_N untersuchen
TODO: Precision vs. Novelty plotten (Recall ist weniger wichtig)
TODO: grid search?
TODO: F1 performance metrik anschauen

In dieser Grafik ist die precision dem recall der trainierten Modelle gegenübergestellt. Dabei wurde für jedes Modell für die in Zahlen angegebenen n-recommendations trainiert und dargestellt. Dabei wurde 10 fold cross validation angewandt. Nun stellt sich die Frage, ob precision, recall, oder beide Masse als wichitg empfunden werden. Precision ist umgekehrt proportional zu false positives, recall zu false negatives. Da es wichtiger ist, dass die gemachten Empfehlungen korrekt sind, nehme ich Precision als Performance Metrik.

Das beste daraus resultierende Modell ist in dem Falle "popular items" mit n=10 Nachbaren.

```{r}



```

***
## Implementierung Ähnlichkeitsmatrix

```{r}

```

TODO: alles hier hin verschieben

***
## Implementierung Top-N Metriken
#### Catalog coverage and System-level novelty
```{r}
rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center', 'Z-score'

df_coverage <- show_coverage(c(5,10,15,20,25,30), rec)
df_novelty <- show_novelty(c(5,10,15,20,25,30), rec)

df_combined <- inner_join(df_coverage, df_novelty, by = 'N')
df_combined
```
Coverage: Summe aller unterschiedlichen Produkte, welche in den Top-N Listen aller Kund*Innen ingesamt auftauchen dividiert durch die Menge aller Produkte.
Novelty: Mittel der Shannon Information der Popularität der Produkte in der Top-N Liste gemittelt über alle Kund*Innen. 

```{r}
ggplot(data=df_combined, aes(x=coverage, y=novelty, group=1)) +
  geom_line() +
  geom_text(aes(label=N), vjust=-.25, hjust=-.05, show.legend = FALSE) +
  labs(
    title = "Coverage gegenüber Novelty für verschiedene N",
    y = "Novelty",
    x = "Coverage"
  ) +
  theme(text = element_text(size = 12))
```
TODO: das ganze im selben plot für verschiedene reduktionen darstellen

***
## Implementierung Top-N Monitor
#### Fixiere 20 zufällig gewählte Testkunden für alle Modellvergleiche
#### Bestimme den Anteil der Top-N Empfehlung nach Genres pro Kunde
```{r}
rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE))
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
show_genre_fraction_plot(df_user_genres_top_n, df_user_genres_top_n$count_top_n, "Anteil Genres in Top-N Empfehlung von 20 zuf. Kunden")
```
Auf diesem Plot ist die Unterschiedliche Verteilung der Genres in den Top-N Empfehlungen für die verschiedenen Kunden zu sehen. Es fällt auf, dass bei diesem Recommender durchaus verschiedenartige Verteilungen bei den Genres für die verschiednen Nutzer auftreten.

#### Bestimme pro Kunde den Anteil nach Genres seiner Top-Filme (=Filme, welche vom Kunden die besten Bewertungen erhalten haben)
```{r}
df_user_genres_best <- create_df_user_genres_best(movies, df_user_genres_top_n, genres)
show_genre_fraction_plot(df_user_genres_best, df_user_genres_best$count_best, "Anteil Genres der bestbewerteten Filme von 20 zuf. Kunden")
```
Auf diesem Plot ist die Unterschiedliche Verteilung der Genres bei den bestbewerteten Filmen für die verschiedenen Kunden zu sehen. Bestbewertet bedeutet in diesem Fall, dass die Bewertung eines Filmes mindestens 0.5 höher sein muss, als die Durchschnittliche Bewertung des Nutzers. Es fällt auf, dass bei den Top-N Empfehlungen allgemein Action zu wenig empfohlen wurde. Comedy hingegen wurde häufig zu viel empfohlen. Bei genauerem betrachten fällt auf, dass dieser Recommeder beispielsweise bei Kunde Nr. 38 auf die Genres bezogen sehr schlechte Empfehlungen macht.

#### Vergleiche pro Kunde Top-Empfehlungen und Top-Filmen nach Genres
```{r fig.width = 7.5, fig.height = 6}
df_user_genres_best <- create_df_user_genres_best(movies, df_user_genres_top_n, genres)

rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE))
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
show_cleveland_dot_plot(df_user_genres, 'IBCF Recommender mit Cosine Similarity')
```
Auf diesem Plot ist ersichtlich welche Genres der IBCF Recommender mit Cosine Similarity für die 20 Kunden eher zu wenig oder zu viel empfielt. Beispielsweise Comedy macht bei den bestbewerteten Filmen im Durchschnitt ungefähr 12% aus, erscheint in den Top-N Empfehlungen jedoch zu etwa 21%.


```{r fig.width = 7.5, fig.height = 6}
rec <- Recommender(train, method = "UBCF", param=list(method="Jaccard", normalize = NULL))
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
show_cleveland_dot_plot(df_user_genres, 'UBCF Recommender mit Jaccard Similarity')
```

```{r fig.width = 7.5, fig.height = 6}
rec <- Recommender(train, method = "POPULAR")
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
show_cleveland_dot_plot(df_user_genres, 'Popular Recommender')
```


#### Definiere eine Qualitätsmetrik für Top-N Listen und teste sie
```{r}

algorithms <- list(
  "IBCF cosine" = list(name="IBCF", param=list(k = 30, method = "cosine", normalize = NULL, na_as_zero = TRUE), desc = 'IBCF Recommender mit Cosine Similarity'),
  "UBCF Jaccard" = list(name="UBCF", param=list(method = "jaccard"), desc = 'UBCF Recommender mit Jaccard Similarity'),
  "Popular" = list(name="POPULAR", param=NULL, desc = 'Popular Recommender')
)

errors <- vector()
algos <- vector()
for (algo in algorithms) {
  rec <- Recommender(train, method = algo$name, param=algo$param)
  df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
  df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
  error <- compute_mean_absolute_percentage_error(df_user_genres)
  algos <- c(algos, algo$desc)
  errors <- c(errors, error)
}

df_error <- data.frame(description = algos, error = errors)


ggplot(df_error, aes(x=description, y = error)) + 
  geom_col(fill = 'steelblue') +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  labs(
    title = "Mittlerer absoluter prozentualer Fehler der \nGenre-Anteile in den Top-N Empfehlungen",
    x = element_blank(), 
    y = "Mittlerer absoluter prozentualer Fehler",
    fill = element_blank()
  ) +
  scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
                    )+
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
abs(df1_drama - df2_drama) + abs(df1_actions - df2_action) + ...

















```{r}

image(as(rec@model$sim, "realRatingMatrix"))
#similarity

```



```{r}

#image(as(similarity(train, method = "Cosine", which = "items"), "matrix"))

# plotSimilarityMatrix(train, y = NULL, clusLabels = NULL, colX = NULL, colY = NULL, myLegend = NULL, fileName = "posteriorSimilarityMatrix", savePNG = FALSE, semiSupervised = FALSE, showObsNames = FALSE, clr = FALSE, clc = FALSE, plotWidth = 500, plotHeight = 450)

#dim(as.matrix(subset(movies_wider, select = -c(user))))

#sample <- movies_wider[, colnames(movies_wider) != 'user']
#sample <- sample[, sample(ncol(sample), size=100)]

#sample_matrix <- as.matrix


# reduce samples to 100 users
set.seed(123)
sample_corr <- movies %>% group_by(item) %>% summarize(mean(rating)) %>% sample_n(100, replace=TRUE)
#true_positives <- relevant %>% sum(rating >= threshold)
#false_positives <- relevant %>% sum(rating < threshold)

# convert dataframe back to realRatingMatrix
sample_corr_df <- as(sample_corr, 'data.frame')
# also generate matrix equivalent
sample_corr_matrix <- as(sample_corr, 'matrix')

sample_corr_df
```



```{r}

cosine_sim <- function(A, B)
{
  similarity <- A %*% B / (norm(A, type="2") * norm(B, type="2"))
  return(similarity)
}

cosine_sim2 <- function(A, B)
{
  zae <- A %*% t(B)
  nen1 <- A %*% t(A)
  nen2 <- B %*% t(B)
  nen <- sqrt(diag(nen1) %*% t(diag(nen2)))
  print(dim(zae))
  print(dim(nen))
  similarity <- zae / nen
  return(similarity)
}

jaccard_sim <- function(A, B)
{
  inter = length(intersect(A, B))
  union = length(A) + length(B) - inter
  jac = inter / union
  return (jac)
}

jaccard_sim2 <- function(A, B)
{
  inter <- A %*% t(B)
  B_rev <- (1 - B)
  int_r <- ((1 - A) %*% t(1 - B))
  nom <- dim(A)[2] - int_r
  jac <- inter / nom
  
  return (jac)
}


A <- c(5, 3, 2, 1)
B <- c(1, 2, 3, 4)

cosine_sim(A, B)
jaccard_sim(A, B)
#library(lsa)
#cosine(A, B)

```


```{r}
# normalize=null, na_as_zero=true
similarity <- as.matrix(rec@model$sim)
dim(similarity)
image(rec@model$sim)

```

cosine diy implementation


```{r}

# replace nas with 0 (no adjusted cosine similarity)
sample_matrix_zero <- sample_matrix
sample_matrix_zero[is.na(sample_matrix_zero)] <- 0

# ibcf, because columns are taken here
# row count
#len <- dim(wide_matrix)[2]
#res <- diag(len)

#for(i in 1:len)
#{
#  for(j in 1:len)
#  {
#    if(i < j & i != j)
#    {
#      res[i,j] <- cosine_sim(wide_matrix[,i], wide_matrix[,j])
#      res[j,i] <- res[i,j]
#    }
#  }
#}

cosine_sim_matrix <- cosine_sim2(t(sample_matrix_zero), t(sample_matrix_zero))

dim(cosine_sim_matrix)
cosine_sim_matrix[1:5, 1:5]

```

cosine recommenderlab implementation


```{r}

rec <- Recommender(as(train, "realRatingMatrix"), method = "IBCF", param=list(method="Cosine", k=100, normalize = NULL, na_as_zero = TRUE))
#image(rec@model$sim)
rec_df <- as(rec@model$sim, 'data.frame')

levelplot(rec_df)

```



```{r}
#cosine_sim(wide_matrix[,1], wide_matrix[,2])
#wide_matrix[2,1]
#as.matrix(subset(movies_wider, select = -c(user)))[,2]

cosine_sim <- as.data.frame(cosine_sim_matrix)
dim(df_res)
#image(as(res, "matrix"))
image(as(res, "realRatingMatrix"))
#as(df_test, 'realRatingMatrix')
#ggplot(df_res, aes(x = x_variable, y = y_variable)) + stat_density2d(aes(fill = ..density..), contour = F, geom = 'tile')

```

Compare matrix similarity with implementations in recommenderlab

```{r}
max(abs(Matrix(newmatrix) - mymatrix))
```



```{r}

rownames(res) <- c()
colnames(res) <- c()

levelplot(res)
```


```{r}

xy <- as(rec@model$sim, "matrix")
rownames(xy) <- c()
colnames(xy) <- c()

len <- length(xy)
levelplot(xy[len-10:len-1, len-10:len-1])

```


```{r}
# binarize matrix and make split at a rating of 3
sample_bin <- as(binarize(as(sample_matrix, "realRatingMatrix"), minRating=3), "matrix") * 1

# replace nas with 0 (no adjusted cosine similarity)
#wide_matrix[is.na(wide_matrix)] <- 0

# ibcf, because columns are taken here
# row count

# len <- dim(sample_bin)[2]
# res <- diag(len)
# 
# for(i in 1:len)
# {
#   for(j in 1:len)
#   {
#     if(i < j & i != j)
#     {
#       res[i,j] <- jaccard_sim(sample_bin[,i], sample_bin[,j])
#       res[j,i] <- res[i,j]
#     }
#   }
# }

jac_own <- jaccard_sim2(sample_bin, sample_bin)

jac_own[1:10, 1:10]

#dim(wide_matrix)

```

```{r}
levelplot(jac_own[1:10, 1:10])
#image(as(jac_own, "realRatingMatrix"))
```





###### SPielwiese
```{r}

ggplot(movies, aes(x=item, y=user, colour=rating)) + geom_point(alpha=1, size = 0.05) + theme_classic()

```





