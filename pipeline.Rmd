---
title: "Collaborative Movie Recommender"
author: "Pascal Berger, Lea Bütler & Joël Grosjean"
output:
  html_notebook: default
  pdf_document: default
---
R-Version: **[Default] [32-bit] C:\\Program Files\\R\\R-4.1.0**

```{r echo=FALSE, cache=FALSE, results=FALSE, comment=FALSE, warning=FALSE}
# nötige Packete
packages <- c("tidyverse", "data.table", "lubridate", "ggplot2", "ggthemes", "recommenderlab", "knitr", 'pals', 'RColorBrewer', 'lattice', 'grid', 'gridExtra')

# Noch nicht installierte Pakete installieren
installed_packages <- packages %in% rownames(installed.packages())

if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Laden der Packete
invisible(lapply(packages, library, character.only = TRUE))

# Importieren von Funktionene aus helper file
source("helper.R")

# change options
options(dplyr.summarise.inform = FALSE)
```

***
#### data wrangling
```{r}
# Daten importieren
data(MovieLense)

# dataframe erstellen
movies <- as(MovieLense, "data.frame")
movies <- movies %>% mutate_if(is.character, as.factor)

# breite version des dataframe erstellen
movies_wider <- pivot_wider(
  movies,
  id_cols = user,
  names_from = item,
  values_from = rating,
  values_fill = NULL,
)
```

***
## Explorative Datenanalyse
```{r}
df_1 <- movies %>% group_by(item) %>%  summarize(mean_rating = mean(rating)) %>% sample_n(15) %>% arrange(desc(mean_rating))

ggplot(df_1, aes(y = reorder(item, +mean_rating), x = mean_rating)) +
  geom_col(alpha = 1, fill = 'steelblue') +
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(mean_rating,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Durchschnittliche Filmbewertung",
    subtitle = "Zufällige Stichprobe von 15 Filmen",
    y = element_blank(),    x = "Dirchschnittlich Bewertung in Sternen"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )

```
TODO: beschreiben was das bringt


***
#### 1. Welches sind die am häufigsten geschauten Genres / Filme?
```{r}
movies_genre <- MovieLenseMeta %>%
  rename(item = title)
movies_genre$url <- NULL
movies_genre[movies_genre == 0] <- NA
a <- which(movies_genre==1,arr.ind=TRUE)
movies_genre[a] <- names(movies_genre)[a[,"col"]]
movies_genre <- movies_genre %>%
  unite("genres", unknown:Western, sep= ",", 
        remove = TRUE, na.rm = TRUE)
genres<-merge(x=movies,y=movies_genre,by="item",all.x=TRUE)%>%
  mutate(genres = strsplit(as.character(genres), ",")) %>%
  unnest(genres)

df1a <- movies%>%
  group_by(item)%>%
  summarize(count=n())%>%
  ungroup()%>%
  arrange(desc(count))

df1a <- head(df1a, 10)

df1a %>%
  mutate(item = fct_reorder(item, count))%>%
  ggplot(aes(x = count, y = item))+
  geom_col(alpha = 1, fill = 'steelblue')+
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(count,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Meist bewertete Filme",
    y = element_blank(),    x = "Anzahl Bewertungen"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )
```
Da in unserem Datensatz nur die Anzahl Ratings von Filmen gegeben ist, gehen wir davon aus, dass die meist bewerteten, auch die am meist geschauten Filme sind. In der Grafik sieht man die 10 meist bewerteten Filme.

```{r}
df1b <- genres%>%
  group_by(genres)%>%
  summarize(count=n())%>%
  ungroup()%>%
  arrange(desc(count))

df1b%>%
  mutate(genres = fct_reorder(genres, count))%>%
  ggplot(aes(x = count, y = genres))+
  geom_col(alpha = 1, fill = 'steelblue')+
  geom_text(aes(label=round(count,2)), hjust = -0.2, color = 'black') +
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0), limits = c(0,45000)) +
  geom_text(aes(label=count,2), hjust = 1.3, color = 'white') +
  labs(
    title = "Meist bewertete Genres",
    y = element_blank(),    x = "Anzahl Bewertungen"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )
```
Auch hier wird davon ausgegangen, dass die enres, welche am häufigsten bewertet wurden auch am häufigst geschaut wurden. In der Grafik ist zu sehen, dass Drama das top Genres ist, gefolgt von Comedy und Action.

***
#### 2. Wie verteilen sich die Kundenratings gesamthaft und nach Genres?
```{r}
ggplot(movies, aes(x = rating)) +
  geom_bar(alpha = 1, fill = 'steelblue') +
  geom_text(stat='count', aes(label=..count..), vjust=1.5, color = 'white') +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung Kundenratings gesamthaft",
    subtitle = paste("N = ", nrow(movies), " Bewertungen"),
    x = "Kundenbewertungen", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  theme_classic() +
  theme(
    text = element_text(size = 12)
  )
```
In dieser Grafik ist die Verteilung der bewertungen zu sehen. Die Bewertungen 4 und 5 wirden klar am häufigsten vergeben, wobei 1 und 2 eher selten bewertet werden.

```{r warning=FALSE, fig.width = 15, fig.height = 11}
# get rating count per user, add as column for further processing
counts <- movies %>% group_by(user) %>% count()
movies2 <- merge(movies, counts, by="user")
movies_wider2 <- merge(movies_wider, counts, by="user")

# avoid users with almost no ratings, use median as threshold
median_count <- median(counts$n)

# get sample
set.seed(623)
movies_sample <- movies_wider2 %>% filter(n > median_count) %>% sample_n(5)

# create long table
movies_sample_long <- filter(movies2, user %in% movies_sample$user)

# drop item names, 
movies_sample_long <- subset(movies_sample_long, select = -c(item))

df2b <- genres%>%
  group_by(genres)
  
movies_sample_long_grouped <- movies_sample_long %>% group_by(user, rating) %>% summarise(rating_dens = length(user) / first(n), user = first(user), n=first(n), rating = first(rating))
  
ggplot(genres, aes(x = rating, fill = genres)) +
  geom_bar(alpha = 1, bins = 10) +
  facet_wrap(~genres)+
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung Kundenratings nach Genres",
    subtitle = paste("N = ", nrow(movies), " Bewertungen"),
    x = "Durchschnittliche Bewertung", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  theme(
    text = element_text(size = 12),
    legend.position = 'none'
  )
```
Hier ist zu sehen, dass das Genres Drama am meisten bewertet wurde, wobei Dokumentationen am wenigsten Bewertungen erhalten haben. Die Bewertungen pro Genres verteilen sich jeweils sehr ähnlich. Die Verteilungen der einzelnen Genres sind ebenfalls ähnlich verteilt wie die bewertungen gesamthaft.

***
#### 3.Wie verteilen sich die mittleren Kundenratings pro Film?
```{r}
df3 <- movies %>% 
  group_by(item) %>%  
  summarize(
    mean_rating = mean(rating),
    ratings = n()
  ) %>% 
  mutate(
    more_than_50 = ifelse(ratings >= 50, 'b) mehr als 50 Bewertungen', 'a) weniger als 50 Bewertugen')
  )

ggplot(df3, aes(x = mean_rating)) +
  geom_histogram(alpha = 1, fill = 'steelblue', binwidth = 0.06) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung mittlere Kundenratings pro Film",
    subtitle = paste("N = ", nrow(df3), " Filme"),
    x = "Durchschnittliche Bewertung", 
    y = "Dichte"
  ) +
  theme_classic() +
  theme(text = element_text(size = 12)
  )
```
In dieser Grafik ist die durchschnittliche Bewertung pro Film zu sehen, wobei auch hier zu sehen ist ,dass die die meisten Filme eine Durchschnittliche Bewertung von ca. 3 - 3.5 haben.

```{r}
ggplot(df3, aes(x = mean_rating, fill = more_than_50)) +
  geom_density(alpha = 0.5, bw = 0.08) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung mittlere Kundenratings pro Film",
    subtitle = "N = 1664 Filme",
    x = "Durchschnittliche Bewertung", 
    y = "Dichte",
    fill = element_blank()
  ) +
  theme_classic() +
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
Für diese Grafik wurden die Filme in zwei gruppen unterteilt: Filme die weniger als 50 bewertungen erhalten haben, und Filme welche mehr als 50 Bewertungen erhalten haben. In der Grafik ist imernoch die durchschnittliche Bewertung dieser Filme zu sehen wobei deutlich erkannt werden kann, dass filme welche weniger bewertungen erhalten haben, tendenziell auch schlechter bewertet wurden.

***
#### 4.Wie stark streuen die Ratings von individuellen Kunden?
```{r}
# Number of ratings per user per rating value
movies_sample_long_grouped <- movies_sample_long %>% group_by(user, rating) %>% summarise(rating_dens = length(user) / first(n), user = first(user), n=first(n), rating = first(rating))
```
```{r}
movies_span <- movies %>% group_by(user) %>% 
  summarize(mean = mean(rating), min = min(rating), max = max(rating), span = (max(rating) - min(rating)))

set.seed(123)

ggplot(movies_span  %>% group_by(span) %>% summarise(count = n()), aes(x=span, y=count)) +
  geom_col(fill = 'steelblue') +
  scale_y_continuous(limits = c(0,800), expand = c(0,0)) +
  geom_text(aes(label=round(count,2)), vjust = -0.7, color = 'black') +
  labs(
    title = "Spannweite Kundenratings",
    subtitle = "",
    x = "Spannweite", 
    y = "Anzahl User"
  )+
    theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
  
```
In diesen Grafiken sehen wir detailliertere Informationen über die Spannweite und den Mittelpunkt. In der ersten Übersicht ist die Spannweite und der Mittelpunkt einzelner Kunden dargestellt. Es fällt auf, dass trotz des teilweise relativ hohem Mittelwert alle Ratings von 1-5 abgegeben wurden. Ein rating von 5 wurde sozusagen immer abgegeben, 1 nicht immer.
In der zweiten Übersicht ist die Spannweite aller Kunden dargestellt. Hier wird sichtbar, dass die meisten Kunden Bewertungen von 1-5 abgegeben haben (Spannweite=4), und nur weinige sehr homogen bewertet haben (Spannweite = 1-2). Eine kleine Spannweite kann hier auch aufgetreten sein, da diese User sehr wenige Bewertungen abgegeben haben.

***
#### 5.Welchen Einfluss hat die Normierung der Ratings pro Kunde auf deren Verteilung?
```{r}
movies_sample_long_grouped <- movies %>% group_by(rating) %>% summarise(rating_dens = n())

ggplot(movies_sample_long_grouped, aes(x=rating, y = rating_dens)) + 
  geom_col(fill = 'steelblue') +
  scale_y_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(rating_dens,2)), vjust = 1.5, color = 'white') +
  labs(
    title = "Häufigkeit der Kundenbewertungen",
    subtitle = "N = 943 Kunden",
    x = "User Bewertung (1-5)", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
                    )+
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
TODO: ANzahl RAtings, N = Anzahl Ratings

```{r}
MovNorm <- normalize(MovieLense, method="Z-score")
mov <- as(MovNorm, "data.frame")

ggplot(mov, aes(x=rating)) + 
  geom_histogram(fill = 'steelblue', bins = 70) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Häufigkeit der Kundenbewertungen",
    subtitle = "N = 943 Kunden",
    x = "User Bewertung Normiert", 
    y = "Anzahl",
    fill = element_blank()
  ) +
  scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
                    )+
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
TODO: N = Anzahl Ratings

Die Ratings sind nun ungefähr Normalverteilt mit einem Durchschnittsrating von 0 und einer Standardabweichung von 1. 
Erkennbar ist, dass die Verteilung rechtssteil und linksschief ist, also mehrheitlich positive Bewertungen abgegeben wurden. 
Durch die Normierung der Daten werden die Ratings jedes Users auf dieselbe Verteilung gestaucht, wodurch man die Verteilung aller Daten analysieren kann. Dadurch hat man beispielsweise die Möglichkeit die durchschnittliche Bewertungstendenz herauszufinden. 

***
#### 6.Welche strukturellen Charakteristika (z.B. Sparsity) und Auffälligkeiten zeigt die User Item Matrix?
```{r}
image(MovieLense, main = "Raw Ratings")
# MovieLenseNorm <- normalize(MovieLense, method="Z-score")
```
Users mit tiefen ID's und Filme mit hohen ID's weisen weniger ratings auf. Filme mit tiefer ID jedoch sehr viele.
Auffallend ist, dass es einige wenige User gibt, die fast alle Filme bewertet haben (erkennbar durch die horizontalen scharzen Striche). Dies scheinen sehr aktive Bewerter zu sein.
Viele Users haben jedoch nur einen kleinen Teil der Filme bewertet.
Bei den Filmen ist eine ähnliche Tendenz wahrzunehmen, jedoch sind die vertikalen Striche breiter. Möglicherweise sind dort einige beliebte Filme zusammengefasst.

TODO: Sparcity anzeigen
TODO: Colorbar entfernen

***
## Datenreduktion
```{r}
ratingMatrix <- data_reduction_dense(MovieLense)
ratingMatrix
```

```{r}
show_sparsity_change(MovieLense, random_matrix)
```

```{r}
dense_reduction <- data_reduction_dense(MovieLense)
dense_reduction

dense_user_reduction <- data_reduction_dense_user(MovieLense)
dense_user_reduction

random_reduction <- data_reduction_random(MovieLense)
random_reduction
```

```{r}
matrices <- c('Original Matrix (MovieLense)', 'dense_reduction', 'dense_user_reduction', 'random_reduction')
sparsities <- c(get_sparsity(MovieLense), get_sparsity(dense_reduction), get_sparsity(dense_user_reduction), get_sparsity(random_reduction))

df_sparsity <- data.frame(matrix = matrices, sparsity = sparsities)

ggplot(df_sparsity, aes(x=matrix, y = sparsity)) + 
  geom_col(fill = 'steelblue') +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(sparsity,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Sparsity der verschiedenen Datenreduktionen",
    x = element_blank(), 
    y = "Sparcity in Prozent",
    fill = element_blank()
  ) +
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
Für die dense_reduction sinkt die Sparsity von 93.67% auf 75.80%.
Für die dense_user_reduction sinkt die Sparsity von 93.67% auf 88.18%.
Für die random_reduction bleibt die Sparsity praktisch unverändert. Sie sinkt von 93.67% auf 92.75%.

```{r fig.width = 20, fig.height = 5}
p1 <- image(dense_reduction, main = "Raw Ratings for Dense Reduction")
p2 <- image(dense_user_reduction, main = "Raw Ratings for Dense User Reduction")
p3 <- image(random_reduction, main = "Raw Ratings for Random Reduction")

grid.arrange(p1, p2, p3, ncol = 3, nrow = 1)
```
Man sieht sehr klar, dass die matrix nun deutlich weniger sparse ist.

TODO: Plot für verschiedene Datenreduktionen

```{r fig.width = 15, fig.height = 11}
p1 <- show_change_of_rating_distribution(MovieLense, dense_reduction, 'Für dense_reduction, N alte Matrix = 1664 Filme, N neue Matrix = 700 Filme')
p2 <- show_change_of_rating_distribution(MovieLense, dense_user_reduction, 'Für dense_user_reduction, N alte Matrix = 1664 Filme, N neue Matrix = 700 Filme')
p3 <- show_change_of_rating_distribution(MovieLense, random_reduction, 'Für random_reduction, N alte Matrix = 1664 Filme, N neue Matrix = 700 Filme')

grid.arrange(p1, p2, p3, ncol = 2, nrow = 2)
```

***
## Analyse Ähnlichkeitsmatrix
#### 1. Zerlege den reduzierten MovieLense Datensatz in ein disjunktes Trainings- und Testdatenset im Verhältnis 4:1
```{r}
both <- split_dataset(ratingMatrix, 0.8)
train <- both[[1]]
test <- both[[2]]

print('Trainingsdatenset:')
dim(train)
print('')
print('Testdatenset:')
dim(test)
```

***
#### 2. Trainiere ein IBCF Modell mit 30 Nachbarn und Cosine Similarity
```{r}

rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center'
rec

# predict top 10 movies for 100 users
pre <- predict(rec, test, n = 10)
pre

reco_list <- as(pre, "list")

# top 10 recommendations for the 13th user in reco_list
reco_list[13]

#image(as(pre, "matrix"))

```
***
#### 3. Bestimme die Verteilung der Filme, welche bei IBCF für paarweise Ähnlichkeitsvergleiche verwendet werden
```{r}
model <- getModel(rec)
colSum <- colSums(model$sim > 0)

df <- as.data.frame(colSum)

# add index column
df <- cbind(item = rownames(df), df)
rownames(df) <- 1:nrow(df)

ggplot(df, aes(x = colSum)) +
  geom_histogram(alpha = 1, fill = 'steelblue', binwidth = 2) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung der Anzahl ähnlicher Filme",
    # subtitle = paste("N = ", nrow(df3), " Filme"),
    x = "Anzahl Filme bei denen der Film als Nachbar auftaucht", 
    y = "Häufigkeit"
  ) +
  theme_classic() +
  theme(text = element_text(size = 12)
  )

# ggplot(movies_sample_long_grouped, aes(x=rating, y = rating_dens)) + 
#   geom_col(fill = 'steelblue') +
#   scale_y_continuous(expand = c(0,0)) +
#   labs(
#     title = "Häufigkeit der Kundenbewertungen",
#     subtitle = "N = 943 Kunden",
#     x = "User Bewertung (1-5)", 
#     y = "Anzahl",
#     fill = element_blank()
#   ) +
#   scale_fill_manual("legend", values = c("cyan3", "cyan4", "darkolivegreen3", "darkolivegreen", "coral4")
#                     )+
#   theme_classic() + 
#   theme(
#     text = element_text(size = 12),
#     legend.position = 'bottom'
#   )
```
TODO: gute beschreibung

***
#### 4. Bestimme die Filme, die am häufigsten in der Cosine-Ähnlichkeitsmatrix auftauchen und analysiere deren Vorkommen und Ratings im reduzierten Datensatz
```{r}
df1 <- df %>% arrange(desc(colSum)) %>% head(10)

ggplot(df1, aes(x = colSum, y = reorder(item, +colSum)))+
  geom_col(alpha = 1, fill = 'steelblue')+
  scale_y_discrete(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  geom_text(aes(label=round(colSum,2)), hjust = 1.3, color = 'white') +
  labs(
    title = "Häufigste Filme in Cosine-Ähnlichkeitsmatrix",
    y = element_blank(),
    x = "Anzahl Filme in deren Nachbarschaft der Film ist"
  ) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank(),
        text = element_text(size = 12) # text size
  )
```

```{r}
top10 <- as.list(df1)$item

data <- as(ratingMatrix, "data.frame")
data1 <- data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating)) %>%
  arrange(desc(mean_rating)) %>%
  mutate(category = ifelse(item %in% top10, 'Häufigste 10 Filme', 'Restliche Filme'))

ggplot(data1, aes(x = mean_rating, fill = category)) +
  geom_density(alpha = 0.5, bw = 0.05) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung mittlere Kundenratings pro Film",
    x = "Durchschnittliche Bewertung",
    y = "Dichte",
    fill = element_blank()
  ) +
  theme_classic() +
  theme(
    text = element_text(size = 12),
    legend.position = c(.14, .93)
  )
```
Es fällt auf, dass die häufigsten Filme allgemein sehr gut bewertet werden.

***
##Analyse Top-N Listen - IBCF vs. UBCF
####1.Berechne Top-15 Empfehlungen für Testkunden mit IBCF und UBCF
```{r}
rec_ibcf <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center'
topn_ibcf <- predict(rec_ibcf, test, n = 15)
topn_ibcf_list <- as(topn_ibcf, "list")

rec_ubcf <- Recommender(train, method = "UBCF", param=list(method="Cosine", normalize = NULL))
topn_ubcf <- predict(rec_ubcf, test, n = 15)
topn_ubcf_list <- as(topn_ubcf, "list")
```

***
####2.Vergleiche die Top-15 Empfehlungen und deren Verteilung und diskutiere Gemeinsamkeiten und Unterschiede zwischen IBCF und UBCF für alle Testkunden.
```{r}

ibcf_top <- head(sort(colCounts(topn_ibcf), decreasing = TRUE))
ibcf_top



print('most occurring items - UBCF')
ubcf_top <- head(sort(colCounts(topn_ubcf), decreasing = TRUE))
ubcf_top
```
TODO: darstellung als balkendiagramm

Auffällig ist, dass im UBCF die Filme, welche am häufigsten in den Top-15 Empfehlungen auftauchen, wesentlich üfters vorkommen als diese, die im IBCF als am meist vorkommende Filme definiert sind.

```{r}
#get distribution of intersect for each user
#intersect of top 15 recommendations IBCF vs UBCF
#list_comp_ibcf_ubcf <- vector(mode = "list", length = length(topn_ibcf_list))
list_comp_ibcf_ubcf <- list()
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_ubcf_list[n]))) / 15
  list_comp_ibcf_ubcf <- append(list_comp_ibcf_ubcf, intersection)
}

comp_ibcf_ubcf <- data.frame(matrix(unlist(list_comp_ibcf_ubcf), nrow=length(list_comp_ibcf_ubcf), byrow=TRUE))
colnames(comp_ibcf_ubcf) <- c('intersect')
comp_ibcf_ubcf <- comp_ibcf_ubcf %>% group_by(intersect) %>% summarise(count = n()) %>% ungroup()
comp_ibcf_ubcf$intersect <- round(comp_ibcf_ubcf$intersect, digits = 4)
comp_ibcf_ubcf <- transform(comp_ibcf_ubcf, intersect = as.character(intersect))
comp_ibcf_ubcf

ggplot(comp_ibcf_ubcf, aes(x = intersect, y = count)) +
  geom_col(alpha = 1, fill = 'steelblue') +
  geom_text(aes(label=count), vjust=1.5, color = 'white') +
  scale_y_continuous(expand = c(0,0)) +
  labs(
    title = "Verteilung der überschneidung der empfohlenen Filme",
    # subtitle = paste("N = ", nrow(df3), " Filme"),
    x = "Überschneidung in %", 
    y = "Häufigkeit"
  ) +
  theme_classic() +
  theme(text = element_text(size = 12)
  )

```


***
## Analyse Top-N Listen - Ratings
#### Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs UBCF, beide mit ordinalem Rating und Cosine Similarity für alle Testkunden
```{r}
#intersect of top 15 recommendations IBCF vs UBCF cosine similarity
comp_ord_cos<- 0
for (n in 1:length(topn_ibcf_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_list[n]), unlist(topn_ubcf_list[n]))) / 15
  comp_ord_cos <- comp_ord_cos + intersection
}

print('Anteil übereinstimmender Empfehlungen der Top-15 Liste: ' )
comp_ord_cos / length(topn_ibcf_list)

```



***
#### Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs UBCF, beide mit binärem Rating und Jaccard Similarity für alle Testkunden
```{r}
#ibcf recommender with Jaccard similarity
rec_ibcf_jac <- Recommender(train, method = "IBCF", param=list(method="Jaccard", k=30, normalize = NULL, na_as_zero = TRUE))
topn_ibcf_jac <- predict(rec_ibcf_jac, test, n = 15)
topn_ibcf_jac_list <- as(topn_ibcf_jac, "list")

#ubcf recommender with Jaccard similarity
rec_ubcf_jac <- Recommender(train, method = "UBCF", param=list(method="Jaccard", normalize = NULL))
topn_ubcf_jac <- predict(rec_ubcf_jac, test, n = 15)
topn_ubcf_jac_list <- as(topn_ubcf_jac, "list")

#intersect of top 15 recommendations IBCF vs UBCF Jaccard similarity
comp_bin_jac<- 0
for (n in 1:length(topn_ibcf_jac_list)) {
  intersection <- length(intersect(unlist(topn_ibcf_jac_list[n]), unlist(topn_ubcf_jac_list[n]))) / 15
  comp_bin_jac <- comp_bin_jac + intersection
}

print('Anteil übereinstimmender Empfehlungen der Top-15 Liste: ' )
comp_bin_jac / length(topn_ibcf_jac_list)
```


***
#### Vergleiche den Anteil übereinstimmender Empfehlungen der Top-15 Liste für UBCF mit ordinalem (Cosine Similarity) vs binärem Rating (Jaccard Similarity) für alle Testkunden.
```{r}
#intersect of top 15 recommendations UBCF Cosine Similarity vs UBCF Jaccard similarity
comp_cos_jac<- 0
for (n in 1:length(topn_ubcf_jac_list)) {
  intersection <- length(intersect(unlist(topn_ubcf_jac_list[n]), unlist(topn_ubcf_list[n]))) / 15
  comp_cos_jac <- comp_cos_jac + intersection
}

print('Anteil übereinstimmender Empfehlungen der Top-15 Liste: ')
comp_cos_jac / length(topn_ubcf_jac_list)
```
TODO: balkendiagramm mit verschiedenen Anteilen
TODO: für alle Datenreduktionen

***
##Analyse Top-N Listen - IBCF vs SVD
####1.Vergleiche wie sich der Anteil übereinstimmender Empfehlungen der Top-15 Liste für IBCF vs verschiedene SVD Modelle verändert, wenn die Anzahl der Singulärwerte für SVD von 10 auf 20, 30, 40, 50 verändert wird
```{r}

#dense_reduction, dense_user_reduction, random_reduction

datasets = c(dense_reduction, dense_user_reduction, random_reduction)
datasets[0]
k = c(10, 20, 30, 40, 50)

output <- data.frame('comparison' = character(), 'intersection' = numeric(), 'dataset' = character())
colnames(output) <- c('comparison', 'intersection')

for (d in datasets){
  both <- split_dataset(d, 0.8)
  train <- both[[1]]
  test <- both[[2]]
  print(paste('train', dim(train)))
  print(paste('test', dim(test)))
  
  for (n in k){
    rec_svd <- Recommender(train, method = "SVD", param=list(k = n))
    #topn_svd <- predict(rec_svd, test, n = 15)
    #topn_svd_list <- as(topn_svd, "list")
  }
}

for (d in datasets){
  both <- split_dataset(d, 0.8)
  train <- both[[1]]
  test <- both[[2]]
  for(n in k){
    rec_svd <- Recommender(train, method = "SVD", param=list(k = n ))
    topn_svd <- predict(rec_svd, test, n = 15)
    topn_svd_list <- as(topn_svd, "list")
    
    comp_ibcf_svd <- 0
    for (i in 1:length(topn_ibcf_list)) {
      intersection <- length(intersect(unlist(topn_ibcf_list[i]), unlist(topn_svd_list[i]))) / 15
      comp_ibcf_svd <- comp_ibcf_svd + intersection
    }
    out <- c(paste('IBCF vs. SVD', n, d), round(comp_ibcf_svd / length(topn_ibcf_list), digits = 4), as.character(d))
    output[n/10, ] <- out
    }
  
}
for(n in k){
  rec_svd <- Recommender(train, method = "SVD", param=list(k = n ))
  topn_svd <- predict(rec_svd, test, n = 15)
  topn_svd_list <- as(topn_svd, "list")
  
  comp_ibcf_svd <- 0
  for (i in 1:length(topn_ibcf_list)) {
    intersection <- length(intersect(unlist(topn_ibcf_list[i]), unlist(topn_svd_list[i]))) / 15
    comp_ibcf_svd <- comp_ibcf_svd + intersection
  }
  out <- c(paste('IBCF vs. SVD', n), round(comp_ibcf_svd / length(topn_ibcf_list), digits = 4))
  output[n/10, ] <- out
}
output

```
TODO: in for-loop
TODO: Als df speichern
TODO: balkendiagramm mit verschiedenen Anteilen

```{r}
test_ttsplit <- evaluationScheme(dense_reduction, method="split", train = 0.8, k=1, given=3)
test_ttsplit
```


***
## Wahl des optimalen Recommenders
#### Verwende für die Evaluierung 10-fache Kreuzvalidierung,

```{r echo=FALSE, cache=FALSE, results=FALSE, comment=FALSE, warning=FALSE, message=FALSE}
evaluate_model()
```



Als erstes stellte sich die Frage, ob precision, recall, oder ein kombinierter F1-Score als performance Metrik gewählt werden sollte. Precision ist umgekehrt proportional zu false positive, recall zu false negative Voraussagen. Da es in diesem Fall wichtiger ist, die gemachten Empfehlungen korrekt vorauszusagen, wurde Precision als Performance Metrik definiert. Als zweite Wahl würden wir auf den F1-Score zurückggreifen. Dieser setzt sich aus der Kombination beider Petriken precision und recall zusammen.

Der Parameter goodRating stellt die binäre Grenze dar, bei welcher ein rating als "positiv" bezeichnet werden kann. Wird der Wert höher gesetzt, sinkt die precision und der recall steigt. In dieser Modelloptimierung wurde definiert, dass alle Ratings ab 3 als positiv klassiert werden sollten.

In dieser Grafik ist die precision der novelty der trainierten Modelle gegenübergestellt. Dabei wurde jedes Modell für n-recommendations trainiert und dargestellt. Es wurde 10 fold cross validation verwendet. Die dargestellten Werte visualisieren das arithmetische Mittel der Scores auf den jeweils 10 Testdatensätzen. Dadurch können die Modelle und Parameter unabhängig von der Struktur der Daten miteinander verglichen werden.

Als erstes wurde sichtbar, dass die Modellwahl mehr Einfluss auf die precision des Modell hatte als die n-recommendations. Deshalb wurde nur SVD und popular für weitere Hyperparameteroptimierung angeschaut.

Das SVD Modell wurde hier für verschiedene k's trainiert. Dabei wurde klar, dass ein k~5 die beste precision voraussagt. Jedoch kommt das Modell nicht annähernd an die precision von popular heran.

Das beste daraus resultierende Modell ist in dem Falle "popular items" mit n=10 Voraussagen.



Das popular Modell besitzt keine Hyperparameter für die Optimierung.
Deshalb wird hier SVD bezüglich Hyperparameter k und n im Detail optimiert.

```{r}

hyper_param_svd(seq(from=2, to=10, by=1))

```

Für das Modell SVD ist die Precision am besten, wenn k=4 ist und n=10. 
Zudem wurde festgestellt, dass je nach Seed Position k=5 besser sein kann.
Die precision des Modells mit optimierten Hyperparameter ist immernoch tiefer, als die des popular Modells.


***
## Implementierung Ähnlichkeitsmatrix

Als erstes wird hier ein sample aus 100 zufällig gewähten Filmen gezogen.



```{r}

#image(as(similarity(train, method = "Cosine", which = "items"), "matrix"))

# plotSimilarityMatrix(train, y = NULL, clusLabels = NULL, colX = NULL, colY = NULL, myLegend = NULL, fileName = "posteriorSimilarityMatrix", savePNG = FALSE, semiSupervised = FALSE, showObsNames = FALSE, clr = FALSE, clc = FALSE, plotWidth = 500, plotHeight = 450)

#dim(as.matrix(subset(movies_wider, select = -c(user))))

#sample <- movies_wider[, colnames(movies_wider) != 'user']
#sample <- sample[, sample(ncol(sample), size=100)]

#sample_matrix <- as.matrix


# reduce samples to 100 users
set.seed(123)

mov_sample <- sample(unique(movies$item), size=100)

sample_sim <- movies %>% filter(item %in% mov_sample)

# TODO outer join with users to get nas

length(unique(sample_sim$item))
#true_positives <- relevant %>% sum(rating >= threshold)
#false_positives <- relevant %>% sum(rating < threshold)

# generate matrix equivalent
sample_sim_matrix <- as(sample_sim, 'matrix')
# convert back to real rating matrix
sample_sim_rating <- as(sample_sim, "realRatingMatrix")

# wide version
# breite version des dataframe erstellen
sample_sim_wide <- pivot_wider(
  sample_sim,
  id_cols = user,
  names_from = item,
  values_from = rating,
  values_fill = NULL,
)

sample_sim_wide
```


```{r}

rec <- Recommender(sample_sim_rating, method = "IBCF", param=list(method="Cosine", k=100, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center'
similarity <- as.matrix(rec@model$sim)
#image(similarity)
image(rec@model$sim)

```


```{r}

# replace nas with 0 (non adjusted cosine similarity)
sample_sim_zero <- sample_sim_wide
sample_sim_zero[is.na(sample_sim_zero)] <- 0

# ibcf, because columns are taken here

cosine_sim_matrix <- cosine_sim2(t(sample_sim_zero), t(sample_sim_zero))

dim(cosine_sim_matrix)
cosine_sim_matrix[1:5, 1:5]

```

Hier wurde die cosine similarity als Matrix Berechnung implementiert.

cosine recommenderlab implementation



```{r}
#cosine_sim(wide_matrix[,1], wide_matrix[,2])
#wide_matrix[2,1]
#as.matrix(subset(movies_wider, select = -c(user)))[,2]

#image(as(res, "matrix"))
image(as(cosine_sim_matrix, "realRatingMatrix"))
#as(df_test, 'realRatingMatrix')
#ggplot(df_res, aes(x = x_variable, y = y_variable)) + stat_density2d(aes(fill = ..density..), contour = F, geom = 'tile')

```

Compare matrix similarity with implementations in recommenderlab

```{r}
#max(abs(Matrix(cosine_sim_matrix) - mymatrix))
```



```{r}

rownames(cosine_sim_matrix) <- c()
colnames(cosine_sim_matrix) <- c()

levelplot(cosine_sim_matrix)
```

```{r}

xy <- as(rec@model$sim, "matrix")
rownames(xy) <- c()
colnames(xy) <- c()

len <- length(xy)
levelplot(xy)

```


```{r}
# binarize matrix and make split at a rating of 3
sample_bin <- as(binarize(as(sample_sim_matrix, "realRatingMatrix"), minRating=3), "matrix") * 1

# replace nas with 0 (no adjusted cosine similarity)
#wide_matrix[is.na(wide_matrix)] <- 0

# ibcf, because columns are taken here
# row count



jac_own <- jaccard_sim2(sample_bin, sample_bin)

jac_own[1:10, 1:10]

#dim(wide_matrix)

```

```{r}
levelplot(jac_own[1:20, 1:20])
#image(as(jac_own, "realRatingMatrix"))
```














***
## Implementierung Top-N Metriken
#### Catalog coverage and System-level novelty
```{r}
rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE)) #normalize = 'center', 'Z-score'

df_coverage <- show_coverage(c(5,10,15,20,25,30), rec)
df_novelty <- show_novelty(c(5,10,15,20,25,30))

df_combined <- inner_join(df_coverage, df_novelty, by = 'N')
df_combined
```
Coverage: Summe aller unterschiedlichen Produkte, welche in den Top-N Listen aller Kund*Innen ingesamt auftauchen dividiert durch die Menge aller Produkte.
Novelty: Mittel der Shannon Information der Popularität der Produkte in der Top-N Liste gemittelt über alle Kund*Innen. 

```{r}
ggplot(data=df_combined, aes(x=coverage, y=novelty, group=1)) +
  geom_line() +
  geom_text(aes(label=N), vjust=-.25, hjust=-.05, show.legend = FALSE) +
  labs(
    title = "Coverage gegenüber Novelty für verschiedene N",
    y = "Novelty",
    x = "Coverage"
  ) +
  theme(text = element_text(size = 12))
```
TODO: das ganze im selben plot für verschiedene reduktionen darstellen

***
## Implementierung Top-N Monitor
#### Fixiere 20 zufällig gewählte Testkunden für alle Modellvergleiche
#### Bestimme den Anteil der Top-N Empfehlung nach Genres pro Kunde

TODO: Hier auch 3 mal?
TODO: IBCF im titel erwähnen

```{r}
rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE))
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
show_genre_fraction_plot(df_user_genres_top_n, df_user_genres_top_n$count_top_n, "Anteil Genres in Top-N Empfehlung von 20 zuf. Kunden")
```
Auf diesem Plot ist die Unterschiedliche Verteilung der Genres in den Top-N Empfehlungen für die verschiedenen Kunden zu sehen. Es fällt auf, dass bei diesem Recommender durchaus verschiedenartige Verteilungen bei den Genres für die verschiednen Nutzer auftreten.

#### Bestimme pro Kunde den Anteil nach Genres seiner Top-Filme (=Filme, welche vom Kunden die besten Bewertungen erhalten haben)
```{r}
df_user_genres_best <- create_df_user_genres_best(movies, df_user_genres_top_n, genres)
show_genre_fraction_plot(df_user_genres_best, df_user_genres_best$count_best, "Anteil Genres der bestbewerteten Filme von 20 zuf. Kunden")
```
Auf diesem Plot ist die Unterschiedliche Verteilung der Genres bei den bestbewerteten Filmen für die verschiedenen Kunden zu sehen. Bestbewertet bedeutet in diesem Fall, dass die Bewertung eines Filmes mindestens 0.5 höher sein muss, als die Durchschnittliche Bewertung des Nutzers. Es fällt auf, dass bei den Top-N Empfehlungen allgemein Action zu wenig empfohlen wurde. Comedy hingegen wurde häufig zu viel empfohlen. Bei genauerem betrachten fällt auf, dass dieser Recommeder beispielsweise bei Kunde Nr. 38 auf die Genres bezogen sehr schlechte Empfehlungen macht.

#### Vergleiche pro Kunde Top-Empfehlungen und Top-Filmen nach Genres
```{r fig.width = 7.5, fig.height = 6}
df_user_genres_best <- create_df_user_genres_best(movies, df_user_genres_top_n, genres)

rec <- Recommender(train, method = "IBCF", param=list(method="Cosine", k=30, normalize = NULL, na_as_zero = TRUE))
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
show_cleveland_dot_plot(df_user_genres, 'IBCF Recommender mit Cosine Similarity')
```
Auf diesem Plot ist ersichtlich welche Genres der IBCF Recommender mit Cosine Similarity für die 20 Kunden eher zu wenig oder zu viel empfielt. Beispielsweise Comedy macht bei den bestbewerteten Filmen im Durchschnitt ungefähr 12% aus, erscheint in den Top-N Empfehlungen jedoch zu etwa 21%.


```{r fig.width = 7.5, fig.height = 6}
rec <- Recommender(train, method = "UBCF", param=list(method="Jaccard", normalize = NULL))
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
show_cleveland_dot_plot(df_user_genres, 'UBCF Recommender mit Jaccard Similarity')
```

```{r fig.width = 7.5, fig.height = 6}
rec <- Recommender(train, method = "POPULAR")
df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
show_cleveland_dot_plot(df_user_genres, 'Popular Recommender')
```

TODO: add plot for svd recommender

#### Definiere eine Qualitätsmetrik für Top-N Listen und teste sie
```{r}

algorithms <- list(
  "IBCF cosine" = list(name="IBCF", param=list(k = 30, method = "cosine", normalize = NULL, na_as_zero = TRUE), desc = 'IBCF Recommender mit Cosine Similarity'),
  "UBCF Jaccard" = list(name="UBCF", param=list(method = "jaccard"), desc = 'UBCF Recommender mit Jaccard Similarity'),
  "Popular" = list(name="POPULAR", param=NULL, desc = 'Popular Recommender')
)

errors <- vector()
algos <- vector()
for (algo in algorithms) {
  rec <- Recommender(train, method = algo$name, param=algo$param)
  df_user_genres_top_n <- create_df_user_genres_top_n(rec, genres)
  df_user_genres <- create_df_user_genres(df_user_genres_top_n, df_user_genres_best)
  error <- compute_mean_absolute_percentage_error(df_user_genres)
  algos <- c(algos, algo$desc)
  errors <- c(errors, error)
}

df_error <- data.frame(description = algos, error = errors)


ggplot(df_error, aes(x=description, y = error)) + 
  geom_col(fill = 'steelblue') +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  geom_text(aes(label=error), hjust=1.5, color = 'white') +
  labs(
    title = "Mittlerer absoluter prozentualer Fehler der \nGenre-Anteile in den Top-N Empfehlungen",
    x = element_blank(), 
    y = "Mittlerer absoluter prozentualer Fehler",
    fill = element_blank()
  ) +
  theme_classic() + 
  theme(
    text = element_text(size = 12),
    legend.position = 'bottom'
  )
```
abs(df1_drama - df2_drama) + abs(df1_actions - df2_action) + ...








###### SPielwiese
```{r}

ggplot(movies, aes(x=item, y=user, colour=rating)) + geom_point(alpha=1, size = 0.05) + theme_classic()

```





